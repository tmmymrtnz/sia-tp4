{
    "layer_sizes": [2, 5, 1],
    "activations": ["", "tanh", "sigmoid"],
    "loss": "bce",
    "optimizer": "adam",
    "optim_kwargs": {
      "learning_rate": 0.1
    },
    "batch_size": 4,
    "max_epochs": 10000
  }