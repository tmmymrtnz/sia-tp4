{
    "layer_sizes": [35, 64, 10],
    "activations": ["", "tanh", "sigmoid"],
    "loss": "cross_entropy",
    "optimizer": "adam",
    "optim_kwargs": {
      "learning_rate": 0.01
    },
    "batch_size": 10,
    "max_epochs": 10000,
    "heatmap": false
  }
  