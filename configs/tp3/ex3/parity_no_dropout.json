{
    "layer_sizes": [35, 30, 1],
    "activations": ["", "tanh", "sigmoid"],
    "dropout_rate": 0.0,
    "loss": "mse",
    "optimizer": "adam",
    "optim_kwargs": {
      "learning_rate": 0.01
    },
    "batch_size": 10,
    "max_epochs": 2000
  }